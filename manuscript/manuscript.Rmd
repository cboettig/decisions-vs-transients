---
title: "Consequences of long transients in model inference and optimal control"
date: "`r Sys.Date()`"
author:
  - name: Carl Boettiger
    email: cboettig@berkeley.edu
    affiliation: ucb
    footnote: Corresponding Author
address:
  - code: ucb
    address: "ESPM Department, University of California, 130 Mulford Hall Berkeley, CA 94720-3114, USA"
abstract: |
  I explore the impact of long transient dynamics for model inference and optimal
journal: Theoretical ecology
layout: 5p
bibliography: refs.bib
output: rticles::elsevier_article

---

```{r include = FALSE}
knitr::opts_chunk$set(echo = FALSE, cache = 1,  
                      dev = "cairo_pdf", fig.width=4.5, 
                      fig.height=3.5, message = FALSE,
                      warning = FALSE)
library(hrbrthemes)
library(Cairo)
library(extrafont)
extrafont::loadfonts()


library(ggplot2)
library(ggthemes)
library(ggtext) # devtools::install_github("clauswilke/ggtext")
ggplot2::theme_set(hrbrthemes::theme_ipsum_rc())
pal <- solarized_pal()(3)
```

```{r message = FALSE}
library(tidyverse)   # plotting and data manipulation
```


Long transients may be quite common features of the dynamics of ecological systems [@Hastings1994; @Hastings2018].  What implications does this have for our ability to predict and manage them?  One of the most intuitive implications for the existence of long transients in the risk in mistaking transient behavior for stable state behavior and the consequences of managing a system under this false conclusion.  The potential for this mistake is straightforward to demonstrate even under idealized conditions such as access to accurate, high frequency data and knowledge of the correct model structure. Decision-theoretic approaches to ecological management provide a more nuianced approach for dealing with uncertainty by explicitly considering the set of all actions available to the manager and the likely consequences of those actions over time. In this paper, I explore the ability of both passive and active adaptive management approaches to cope with the challenge of long transient dynamics.  My results underscore the challenge transients create for accurate model inference, but also show a potential way forward for accounting for the resulting uncertainty in a decision-theory framework. Examining the impact different prior beliefs have on adaptive management, I show how a precautionary principle emerges from the optimization.  This analysis also highlights the importance of stochasticity has for transient dynamics.

## Model and Methods

I consider a generic model of population dynamics which can exhibit phenomena such as bistability and a ghost attractor dynamics.  This model is amenable to interpretation in many ecological contexts (sensu @Levins1966 sacrificing precision to realism and generality), such as the collapse of a fish population, recovery of an endagered species, or the outbreak a pest.  To provide a more tangible context to frame our questions of ecological mangement, I will focus on the latter scenario of a pest outbreak.  In this scenario, we imagine a species such as the Pine bark beetle, (e.g. *Dendroctonus ponderosae*, @Harvey2014) whose recent boom in population has devastated much of Northern America's pine forests.  The model is a stochastic version of the consumer-resource model of @May1977,

\begin{equation}
X_{t+1} = X_t + \underbrace{X_t r \left(1 -\frac{X_t}{K} \right)}_{\textrm{logistic growth}}  - 
\underbrace{\frac{a X_t ^ Q}{X_t^ Q + H ^ Q}}_{\textrm{saturating consumption}} + 
\underbrace{\xi_t X_t}_{\textrm{environmental noise}} \label{model}
\end{equation}

Where $X_t$ is the population density of the focal species (the beetle, in our case).  The growth  rate of the species is determined by an intrinsic growth rate $r$ and carrying capacity $K$. The species is under mortality pressure from another species (the natural defences of trees, in our context) which has an S curve saturation which reaches its half maximum at $H$ and maximum rate of $a$.  $Q$ determines the steepness of the saturating response. The dynamics are subject to environmental white noise proportional to the population size, $\xi_t X_t$ [@Boettiger2018]. Model dynamics are illustrated in Figure 1 under two different parameter choices for the saturation response $a$: one which corresponds to a ghost attractor and one to a bistable system.


```{r}
## Model constants -- used to compute transistion probabilities
efficiency <- .4    
p <- list(r = .8, K = 153, q = 2, b = 20, sigma = .02, x0 = 20) # fixed parameters

may <- function(a){  
  function(x, h = 0){ # May
    y <- x - efficiency * h
    pmax(
      ## controlling h is controlling the bifurcation point directly...
      y + y * p$r * (1 - y / p$K)  - a * y ^ p$q / (y ^ p$q + p$b ^ p$q),  
      0)
  }
}
```

```{r figure1, fig.cap="Change in population size $X_{t+1} - X_t = f(X_t)$. Equilibria occur when the change curve crosses zero, stable points arise at crossings with negative slopes, unstable equilibria have positive slopes.  By changing parameter a, the system goes from bistable (red, a = 28.5) to a ghost attractor (blue, a = 27). For both curves, r = 0.8, K = 153, Q = 2, H = 20."}
c(`ghost attractor` = 27,           
  `bistable attractor` = 28.5) %>%
  map_dfr(function(a) tibble(x = states, f = may(a)(x,0) - x, a = a), .id = "scenario") %>% 
  ggplot(aes(x, f)) + 
    geom_line(aes(lty = scenario, col = scenario), lwd = 1) +
    geom_hline(aes(yintercept = 0)) + 
    labs(y = bquote(X[t+1] - X[t]), x = bquote(X[t])) + 
    scale_color_solarized()

```



Under appropriate choice of parameters, the model is bistable, with two stable equilibiria at non-zero population sizes -- a low, "endemic" state, and a much higher "outbreak" state.  In the context of our beetle outbreak question, we will imagine that this model describes the population growth of the beetle over a single season, emergign from some low density following winter die off and growing subject to both it's intrinsic growth rate ($r$) and available resources ($K$) and subject to saturating density-dependent mortality imposed by tree defenses. This saturating response and the resulting threshhold dynamics in the response of affected trees exhibited by this model is quite well motivated   [e.g.@Raffa2008]: affected trees respond to beetle attack by increasing production of resins which can pitch out beetles, inhibit attraction of flying beetles to the tree, and allow other inducible defenses to activate. Initially this results in the strengthening (concave up) portion of the S curve as other defences are induced by the attack.  However, as beetle density increases further, the tree begins to exhaust resources required to produce resin and its other defences, leading to a saturating response.  Low beetle densities are thus stable, kept in check by the increasingly strong response of healthy trees.  Meanwhile, if a tree is overwhelmed, it becomes habitat for spawning many more beetles, which saturate the defences of more trees, leading to the population explosion until beetle numbers reach a much larger stable state by nearly exhausting avaliable tree habitat $K$ [@Harvey2014].    

Thus our simple dynamical model from \eqref{model} captures the qualitative processes and dynamics expected in the beetle outbreak system. Bear in mind that this model is not intended to be a precise, quantitive match that could be fit directly to data, but rather, a theoretical tool to better explore the consequences of this behavior -- a realistic reflection of the process, but also simple enough to generalize to other systems dominated by similar nonlinear dynamics which can drive these threshold responses.

We also observe that by decreasing $a$, the lower stable point vanishes, but the rate of change of the system (e.g. the vertical axis, Figure 1) is still small in magnitude, and thus dynamics near this region move slowly.  This is a simple example of what @Hastings2018 has dubbed a "Ghost Attractor" -- the attractor vanishes at the fold bifurcation, but it's effects can still be felt and observed.  This could result from a weakened ability of the trees to respond to attack, which could result from additional stress such as prolonged drought or fire, both potentially intensified under changing climate.  

Figure 2 illustrates several simulations from the model, starting from a low density, under both the scenario of a stable endemic state and a ghost attractor.  Note that it can in general be quite difficult to distinguish dynamics of the ghost from the dynamics of the stable attractor.  


```{r}
## Discrete version of the state space and action space
n_s <- 121
states <- seq(0, 120, length = n_s)
actions <- seq(0, 120, length = n_s)
```

```{r}
transition_matrix <- function(states, actions, f, sigma){
    n_s <- length(states)
    n_a <- length(actions)
    transition <- array(0, dim = c(n_s, n_s, n_a))
    for(i in 1:n_a){
      for (k in 1:n_s) {
          nextpop <- f(states[k], actions[i])
          if (nextpop <= 0) {
            x  <- c(1, rep(0, n_s - 1))
          } else {
            x <- truncnorm::dtruncnorm(states, 0, max(states), nextpop, sigma * nextpop)
            if(sum(x) <= 0){ 
              x  <- c(1, rep(0, n_s - 1))
            } else {
              x <- x / sum(x)
            }
          }
          transition[k, , i] <- x
      }
  }
  if(any(is.na(transition))) stop("error creating transition matrix")
transition
}
```

```{r}
P_ghost <- transition_matrix(states, actions, may(27.4), p$sigma)
P_bistable <- transition_matrix(states, actions, may(27.6), p$sigma)
```


```{r}
## `actions` is an argument of indices, not necessarily the action values themselves 
sim <- function (transition,  x0, Tmax, action = rep(1, Tmax)){
    n_states <- dim(transition)[2]
    state <- numeric(Tmax + 1)
    state[1] <- x0
    time <- 1:Tmax
    for (t in time) {
        state[t + 1] <- base::sample(1:n_states, 
                               1, 
                               prob = transition[state[t], , action[t]])
    }
    data.frame(time = 1:Tmax, state = state[time])
}
```


```{r}
x0 <- which.min(abs(states - p$x0))
Tmax <- 400
set.seed(1234)
reps <- 50
ghost_sim <- map_dfr(1:reps, function(i)
  sim(P_ghost, x0, Tmax)  %>% mutate(state = states[state], scenario = "ghost"),
  .id = "rep")
bistable_sim <- map_dfr(1:reps, function(i)
  sim(P_bistable, x0, Tmax)  %>% mutate(state = states[state], scenario = "bistable"),
  .id = "rep")

bind_rows(ghost_sim, bistable_sim) %>%
  ggplot(aes(time, state, group = interaction(rep, scenario), col= scenario)) + 
  geom_line(alpha=0.3) + scale_color_solarized() + facet_wrap(~scenario)
```

### Management model

To properly understand the consequences transient dynamics have for management, we must first be more explicit about both the management objectives and potential management actions.  For simplicity, I will imagine a manager has the option to apply a direct mortality to the beetle larvae prior to recruitment, e.g. by spraying at some given intensity. Thus the action space is defined by some measure of spraying effort between 0% and 100%.  The management objectives are defined by a utility function, which trades off the costs of control with the costs of damage due to the outbreak.  Here I assume linearly increasing cost of control (fixed price per unit spraying). Below an endemic population size $X_0$ I assume damage (e.g. no tree mortality) is minimal, and then increases quadratically with increasing beetle density; that is, the instantaneous utility of state with beetle density $X_t$ and taking action $A_t$ is

\begin{equation}
U(X_t, A_t) = \underbrace{ - d \max\left(X_t - X_0, 0\right)^2}_{\textrm{damage}} - \underbrace{c A_t}_{control} \label{utility}
\end{equation}

The manager's objective is to select the sequence of actions $A_t \in \mathbf{A}$ which maximize the net expected discounted ($\delta$) utility, 

$$\max_{A_t \in \mathbf{A}} \sum_t \delta^t U(X_t, A_t)$$
where the evolution of $X_t$ is determined by Eq \eqref{model}. Because \eqref{model} is Markovian in $X_t$ (depending only on $X_t$ and no lagged terms),  this sequential decision problem is known as a Markov Decision Process, or MDP.  By discritizing \eqref{model} to a finite grid of possible states, we can represent the model as a transition matrix between possible states (population sizes) and solve the problem using Stochastic Dynamic Programming (SDP) [@Marescot2013].


```{r}
# Constants in the utility function
damage <- .5
control <- 1
endemic <- 50
discount <- 0.999 # Note that dynamics are not on scale of years but ~ days
reward_fn <- function(x,h) - (damage * pmax(x - endemic, 0)) ^ 2  - (control * h)

reward <- array(dim=c(length(states), length(actions)))
for(i in 1:length(states)){
  for(j in 1:length(actions)){
    reward[i,j] <- reward_fn(states[i], actions[j])
  }
}
```


## Optimal Planning under transient dynamics vs stable state dynamics

First, I will consider the case that in which the manager has been able to accurately infer the dynamics (i.e. correctly estimate the parameters of Eq~\eqref{1}), and assuming the model structure postulated \eqref{1} is correct.  The optimal strategy determined by SDP can be represented as a "policy" function $p(X)$, indicating for each possible state $X$ what the optimal action $\hat A = p(X)$ would be.  Figure 3 displays the numerically computed optimal policy for the system with only a transient.  Though the models differ by only a small amount in a single parameter, because one model corresponds to a system with only a ghost attractor while the other has a stable state attractor, the resulting optimal policy solutions differ significantly.  Intuitively, in the system with stable state dynamics, the manager does not implement any control at low levels, where the presence of the lower stable state will constrain the beetle population to acceptable levels.  Once that lower stable state becomes only a ghost attractor, the optimal solution targets elimination of the beetle even at low densities.  Consequently, the optimal response becomes tightly dependent on our knowledge of the dynamics. 


```{r}
soln_ghost <- mdplearning::mdp_compute_policy(list(P_ghost), reward, discount, max_iter = 1e4, epsilon = 1e-2)
soln_bistable <-mdplearning::mdp_compute_policy(list(P_bistable), reward, discount, max_iter = 1e4, epsilon = 1e-2)
```


```{r}
tibble(state = states,
       ghost = actions[soln_ghost$policy],
       bistable =  actions[soln_bistable$policy]
       ) %>%
  pivot_longer(c(ghost, bistable), 
               names_to="model",
               values_to = "action") %>%
  ggplot(aes(state,action, color = model)) + 
  geom_point(alpha=0.6) + 
  scale_color_solarized()
```

## Planning over uncertainty


The transition matrix is an expression of conditional probability $P(X_{t+1} | X_t,  A_t)$, the probability that a system in state $X_t$ will transition to state $X_{t+1}$ in the next time interval if the manager takes action $A_t$.  If we have $n$ possible states and $m$ possible actions, we have $m$ $n \by n$ matrices for the possible transitions.  The transistion matrix also depends on our knowledge or estimates of the parameters of \eqref{model}. We can represent uncertainty over the models and their parameters as uncertainties as conditional on the model, $M_i$, so that the transistion matrix must then be marganlized over the set of possible models: $$P(X_{t+1} | X_t,  A_t) = \sum_{i} P(X_{t+1} | X_t,  A_t, M_i) P(M_i)$$



```{r}
soln_dist <- mdplearning::mdp_compute_policy(list(P_ghost, P_bistable), reward, discount, 
                                             model_prior = c(0.5, 0.5),
                                             max_iter = 1e4, epsilon = 1e-2)

tibble(state = states,
       action = actions[soln_dist$policy])  %>% 
  ggplot(aes(state, action)) + geom_point()
```

```{r}
set.seed(123456)
Tmax <- 50
df <- mdp_planning(P_ghost, reward, discount, 
                   policy = soln_dist$policy,
                   x0 = x0, Tmax = Tmax)

df %>% 
  mutate(state = states[state], action = actions[action] * 5) %>% 
  select(-obs,-value) %>%
  pivot_longer(-time) %>%
  ggplot(aes(time, value, col=name)) + 
  geom_point() + geom_path()
```




## Adaptive management



This probability thus depends on our prior belief that model $i$ is true, $P(M_i)$.  Not only does this allow our manager to make her decision in to reflect uncertainty over models, but it also suggests that having made that decision and observed the outcomes, the manager can update her belief over possible models according to Bayes Rule, 

$$P(M_i | X_{t+1} ) = \frac{P(X_{t+1} | M_i ) P(M_i)}{P(X_{t+1})}$$
that is, the optimal manager not only plans over the uncertainty, but also learns which model is most likely to be correct over the course of management.  



```{r}
set.seed(123456)
Tmax <- 50
learning <- mdp_learning(list(P_ghost, P_bistable), reward, discount, 
                   model_prior = c(0.5, 0.5),
                   x0 = x0, Tmax = Tmax,
                  true_transition = P_ghost,
                  max_iter = 1e4, epsilon = 1e-2)
                  

```



```{r}
 learning_sim$df %>% 
  select(-value) %>% 
  gather(series, state, -time) %>% 
  ggplot(aes(time, states[state], color = series)) + geom_line()
```



```{r}
learning_sim$posterior %>% 
  data.frame(time = 1:Tmax) %>%
  filter(time %in% c(1,50)) %>%
  gather(param, probability, -time, factor_key =TRUE) %>% 
  mutate(param = as.numeric(param)) %>% 
  ggplot(aes(x = param, y = probability, group = time, alpha = time)) + 
  geom_bar(stat="identity", position = "identity", show.legend = FALSE, fill=pal[1]) + 
   ylim(0,0.3)
```


## Long transients when the underlying model is not known

One of the more intuitive implications of the existence of long transients is the inherent risk in mistaking them for stable state dynamics.  For example, Figure \ref{armina} illustrates how a transient 


### Stochastic dynamics and transients

Stochastic dynamics can weaken the average influence of a ghost attractor, but long transients are still likely.  Stochastic dynamics can also make weak attractors behave essentially as ghost attractors.  


# Methods

Stochastic dynamic programming solutions were computed in R [@R] using value iteration using the package `MDPToolbox` [@Marescot2013; @MDPtoolbox].  Code to reproduce this analysis is available at <https://github.com/cboettig/decisions-vs-transients>



\pagebreak 


# References