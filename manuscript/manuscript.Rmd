---
title: "Ecological management of stochastic systems with long transients"
date: "`r Sys.Date()`"
author:
  - name: Carl Boettiger
    email: cboettig@berkeley.edu
    affiliation: ucb
#    footnote: Corresponding Author
address:
  - code: ucb
    address: "ESPM Department, University of California, 130 Mulford Hall Berkeley, CA 94720-3114, USA"
abstract: |
  Long transients may be common in ecological dynamics, but the implications such dynamics have for ecological management have not been fully explored.  Long transient periods can easily be mistaken for stable-state dynamics, but may require dramatically different management policies.  Here, I explore the optimal management of stochastic ecological systems that may contain either a tipping point or a ghost attractor: an important mechanism which can give rise to long transients. I consider three approaches of increasing sophistication: (1) dynamic management under a fixed model, (2) management that accounts for uncertainty over possible models, and (3) adaptive management that actively learns the correct model over the management process. This analysis confirms the prediction that long transients can create considerable uncertainty and give rise to very different optimal management policies, but also illustrates that dynamic management that can either plan for this uncertainty or actively learn to decrease the uncertainty can promote successful management of long transients.
journal: Theoretical ecology
layout: 3p
bibliography: refs.bib
output: rticles::elsevier_article
keywords: 
  - transients, 
  - optimal control, 
  - adaptive management, 
  - stochasticity, 
  - uncertainty, 
  - ecological management
preamble: |
  \journal{Theoretical Ecology}

## EditorialManager adds its own linenumbers to pdf already
#\usepackage{lineno}
# \linenumbers


---

```{r include = FALSE}
knitr::opts_chunk$set(echo = FALSE, cache = 1,  
                      dev = "cairo_pdf", 
                      fig.width=4.5, 
                      fig.height=3.5, 
                      fig.align = "center",
                      message = FALSE,
                      warning = FALSE)
library(hrbrthemes)
library(Cairo)
library(extrafont)
extrafont::loadfonts()

library(patchwork)
library(ggplot2)
library(ggthemes)
library(ggtext) # devtools::install_github("clauswilke/ggtext")
ggplot2::theme_set(hrbrthemes::theme_ipsum_rc())
pal <- solarized_pal()(7)
scale_colour_discrete <- function(...) scale_colour_solarized()
scale_fill_discrete <- function(...) scale_fill_solarized()
```

```{r message = FALSE}
library(tidyverse)   # plotting and data manipulation
library(mdplearning)
```


Long transients may be quite common features of the dynamics of ecological systems [@Hastings1994; @Hastings2018].  What implications does this have for our ability to predict and manage them?  One of the most intuitive implications for the existence of long transients in the risk in mistaking transient behavior for stable state behavior and the consequences of managing a system under this false conclusion.  The potential for this mistake is straightforward to demonstrate even under idealized conditions such as access to accurate, high frequency data and knowledge of the correct model structure. Decision-theoretic approaches to ecological management provide a more nuanced approach for dealing with uncertainty by explicitly considering the set of all actions available to the manager and the likely consequences of those actions over time. In this paper, I explore the ability of both passive and active adaptive management approaches to cope with the challenge of long transient dynamics.  My results underscore the challenge transients create for accurate model inference, but also show a potential way forward for accounting for the resulting uncertainty in a decision-theory framework. Examining the impact different prior beliefs have on adaptive management, I show how a precautionary principle emerges from the optimization.  This analysis also highlights the importance of stochasticity has for transient dynamics.

## Model and Methods

I consider a generic model of population dynamics which can exhibit phenomena such as bistability and a ghost attractor dynamics.  This model is amenable to interpretation in many ecological contexts (sensu @Levins1966 sacrificing precision to realism and generality), such as the collapse of a fish population, recovery of an endangered species, or the outbreak a pest.  To provide a more tangible context to frame our questions of ecological management, I will focus on the latter scenario of a pest outbreak.  In this scenario, we imagine a species such as the Pine bark beetle, (e.g. *Dendroctonus ponderosae*, @Harvey2014) whose recent boom in population has devastated much of Northern America's pine forests.  The model is a stochastic extension of the deterministic consumer-resource model of @May1977,

\begin{equation}
X_{t+1} = X_t + \underbrace{X_t r \left(1 -\frac{X_t}{K} \right)}_{\textrm{logistic growth}}  - 
\underbrace{\frac{a X_t ^ Q}{X_t^ Q + H ^ Q}}_{\textrm{saturating consumption}} + 
\underbrace{\xi_t X_t}_{\textrm{environmental noise}} \label{model}
\end{equation}

Where $X_t$ is the population density of the focal species (the beetle, in our case).  The growth  rate of the species is determined by an intrinsic growth rate $r$ and carrying capacity $K$. The species is under mortality pressure from another species (the natural defenses of trees, in our context) which has an S curve saturation which reaches its half maximum at $H$ and maximum rate of $a$. Parameter $Q$ determines the steepness of the saturating response. The stochastic formulation follows directly from interpreting May's model as the average dynamics of a process subject to to environmental white noise proportional to the population size, $\xi_t X_t$, uncorrelated Gaussian noise $\xi \sim \mathcal{N}(0,\sigma)$ with mean zero and standard deviation $\sigma$ [@Boettiger2018]. Model dynamics are illustrated in Fig 1 under two different parameter choices for the saturation response $a$: one which corresponds to a ghost attractor and one to a bistable system.


```{r}
## Discrete version of the state space and action space
n_s <- 121
states <- seq(0, 120, length = n_s)
actions <- seq(0, 120, length = n_s)
```

```{r}
## Model constants -- used to compute transistion probabilities
efficiency <- .4    
p <- list(r = .8, K = 153, q = 2, b = 20, sigma = .05, x0 = 20) # fixed parameters

may <- function(a){  
  function(x, h = 0){ # May
    y <- x - efficiency * h
    pmax(
      ## controlling h is controlling the bifurcation point directly...
      y + y * p$r * (1 - y / p$K)  - a * y ^ p$q / (y ^ p$q + p$b ^ p$q),  
      0)
  }
}
```

```{r figure1, fig.cap="Change in population size $X_{t+1} - X_t = f(X_t)$. Equilibria occur when the change curve crosses zero, stable points arise at crossings with negative slopes, unstable equilibria have positive slopes.  By changing parameter $a$, the system goes from bistable (blue, $a = 28$) to a ghost attractor (red, $a = 27.2$). For both curves, $r = 0.8$, $K = 153$, $Q = 2$, $H = 20$."}

## Fig 1

c(`ghost attractor` = 27.2,           
  `bistable attractor` = 28) %>%
  map_dfr(function(a) tibble(x = states, f = may(a)(x,0) - x, a = a), .id = "scenario") %>% 
  ggplot(aes(x, f)) + 
    geom_line(aes(lty = scenario, col = scenario), lwd = 1) +
    geom_hline(aes(yintercept = 0)) + 
    labs(y = bquote(X[t+1] - X[t]), x = bquote(X[t])) + 
    scale_color_solarized()

```



Under appropriate choice of parameters, the model is bistable, with a low, "endemic" stable state, and a much higher stable "outbreak" state.  In the context of our beetle outbreak question, we will imagine that this model describes the population growth of the beetle over a single season, emerging from some low density following winter die off and growing subject to both it's intrinsic growth rate ($r$) and available resources ($K$) and subject to saturating density-dependent mortality imposed by tree defenses. This saturating response and the resulting threshold dynamics in the response of affected trees exhibited by this model is quite well motivated   [e.g. @Raffa2008]: affected trees respond to beetle attack by increasing production of resins which can pitch out beetles, inhibit attraction of flying beetles to the tree, and allow other inducible defenses to activate. Initially this results in the strengthening (concave up) portion of the S curve as other defenses are induced by the attack.  However, as beetle density increases further, the tree begins to exhaust resources required to produce resin and its other defenses, leading to a saturating response.  Low beetle densities are thus stable, kept in check by the increasingly strong response of healthy trees.  Meanwhile, if a tree is overwhelmed, it becomes habitat for spawning many more beetles, which saturate the defenses of more trees, leading to the population explosion until beetle numbers reach a much larger stable state by nearly exhausting available tree habitat $K$ [@Harvey2014]. Thus our simple dynamical model from Eq 1 captures the qualitative processes and dynamics expected in the beetle outbreak system. Bear in mind that this model is not intended to be a precise, quantitative match that could be fit directly to data, but rather, a theoretical tool to better explore the consequences of this behavior -- a realistic reflection of the process, but also simple enough to generalize to other systems dominated by similar nonlinear dynamics which can drive these threshold responses.

Models with this structure are also capable of producing long transient dynamics instead of alternative stable state dynamics by slightly changing the chosen parameter values.  Observe that by decreasing $a$, the lower stable point vanishes, but the rate of change of the system (e.g. the vertical axis, Fig 1) is still small in magnitude, and thus dynamics near this region move slowly.  This is a simple example of a "Ghost Attractor" [@Deco2012] -- the attractor vanishes at the fold bifurcation, but it's effects can still be felt and observed [@Grossman1980; @Hastings2018].  This could result from a weakened ability of the trees to respond to attack, which could result from additional stress such as prolonged drought or fire, both potentially intensified under changing climate.  


This same model structure can thus produce rather different dynamics due to only a small change in a single parameter, as illustrated in the ensemble simulations shown in Fig 2. Each ensemble shows 50 replicate trajectories starting with the same initial condition, under parameters corresponding either to the bistable system (panel A) or the ghost attractor (panel B). Because the model is stochastic, trajectories under the bistable system have some probability of escaping the lower attractor after a sufficient interval.  Thus while it is quite easy to distinguish between the alternate stable state dynamics and the ghost attractor dynamics visually given the ensemble of replicates, given only a single replicate it could be quite difficult to be sure if it came from a particularly long transient or a stochastic escape from a stable node.  



```{r}
transition_matrix <- function(states, actions, f, sigma){
    n_s <- length(states)
    n_a <- length(actions)
    transition <- array(0, dim = c(n_s, n_s, n_a))
    for(i in 1:n_a){
      for (k in 1:n_s) {
          nextpop <- f(states[k], actions[i])
          if (nextpop <= 0) {
            x  <- c(1, rep(0, n_s - 1))
          } else {
            x <- truncnorm::dtruncnorm(states, 0, max(states), nextpop, sigma * nextpop)
            if(sum(x) <= 0){ 
              x  <- c(1, rep(0, n_s - 1))
            } else {
              x <- x / sum(x)
            }
          }
          transition[k, , i] <- x
      }
  }
  if(any(is.na(transition))) stop("error creating transition matrix")
transition
}
```

```{r}
P_ghost <- transition_matrix(states, actions, may(27.2), p$sigma)
P_bistable <- transition_matrix(states, actions, may(28), p$sigma)
```


```{r}
## `actions` is an argument of indices, not necessarily the action values themselves 
sim <- function (transition,  x0, Tmax, action = rep(1, Tmax)){
    n_states <- dim(transition)[2]
    state <- numeric(Tmax + 1)
    state[1] <- x0
    time <- 1:Tmax
    for (t in time) {
        state[t + 1] <- base::sample(1:n_states, 
                               1, 
                               prob = transition[state[t], , action[t]])
    }
    data.frame(time = 1:Tmax, state = state[time])
}
```


```{r}
x0 <- which.min(abs(states - p$x0))
Tmax <- 200
set.seed(12345)
reps <- 50
ghost_sim <- map_dfr(1:reps, function(i)
  sim(P_ghost, x0, Tmax)  %>% mutate(state = states[state], scenario = "ghost"),
  .id = "rep")
bistable_sim <- map_dfr(1:reps, function(i)
  sim(P_bistable, x0, Tmax)  %>% mutate(state = states[state], scenario = "bistable"),
  .id = "rep")

fig1_sims <- bind_rows(ghost_sim, bistable_sim)
write_csv(fig1_sims, "manuscript_cache/fig1_sims.csv")
```

```{r figure2, fig.cap="50 replicate simulations with identical starting conditions ($X_0 = 21$) of each scenario with parameter values as given in Fig 1. While the ensemble of 50 replicates clearly appears more stable than the ghost attractor, individual replicates may be difficult to distingush."}
# Fig 2
fig1_sims %>%
  ggplot(aes(time, state, group = interaction(rep, scenario), col = scenario)) + 
  geom_line(alpha=0.3) + scale_color_solarized() + facet_wrap(~scenario, ncol = 1)
```

This ambiguity is accentuated considerably if we are tasked with forecasting the future behavior having only observed the system during the early part of a trajectory (i.e. in the vicinity of the ghost attractor or lower stable point).  Long transients under the influence of the ghost attractor can easily be mistaken for stable node dynamics, but will have considerably greater probability of suddenly transitioning to the outbreak state than trajectories under alternate stable state dynamics in the short term.  


While it is clear this situation -- in which a ghost attractor could be mistaken for a stable state -- can have important consequences for management, there has been little detailed investigation into precisely what those consequences are or how this uncertainty could be resolved. In the context of our bark beetle model, this corresponds to uncertainty as to whether the forest is healthy enough to contain the currently observed level of beetle activity to an endemic state, or whether the forest has been stressed sufficiently to be headed for a full-scale outbreak and thus warrant a more aggressive pest control response.  

In the remaining sections, we will explore two different approaches to addressing the problem of management under a potential ghost attractor. First, we will examine the decision-theoretic optimal policy for each stochastic model separately, illustrating that the transient system does indeed lead to a different management strategy than the alternate stable state system.  We will then examine the optimal solution when the manager is uncertain which of the two models is the true.  Finally, we will examine an active adaptive management approach, in which the manager updates the probability that each model is true following each iteration of decision and observation.  


### Management model

To properly understand the consequences transient dynamics have for management, we must first be more explicit about both the management objectives and potential management actions.  For simplicity, I will imagine a manager has the option to apply a direct mortality to the beetle larvae prior to recruitment, e.g. by spraying at some given intensity. Thus the action space is defined by some measure of spraying effort between 0% and 100%.  The management objectives are defined by a utility function, which trades off the costs of control with the costs of damage due to the outbreak.  Here I assume linearly increasing cost of control (fixed price per unit spraying). Below an endemic population size $X_0$ I assume damage (e.g. no tree mortality) is minimal, and then increases quadratically with increasing beetle density; that is, the instantaneous utility of state with beetle density $X_t$ and taking action $A_t$ is

\begin{equation}
U(X_t, A_t) = \underbrace{ - d \max\left(X_t - X_0, 0\right)^2}_{\textrm{damage}} - \underbrace{c A_t}_{control} \label{utility}
\end{equation}

The manager's objective is to select the sequence of actions $A_t \in \mathbf{A}$ which maximize the net expected discounted ($\delta$) utility, 

$$\max_{A_t \in \mathbf{A}} \sum_t \delta^t U(X_t, A_t)$$
where the evolution of $X_t$ is determined by Eq \eqref{model}. Because \eqref{model} is Markovian in $X_t$ (depending only on $X_t$ and no lagged terms),  this sequential decision problem is known as a Markov Decision Process, or MDP.  By discritizing \eqref{model} to a finite grid of possible states, we can represent the model as a transition matrix between possible states (population sizes) and solve the problem using Stochastic Dynamic Programming (SDP) [@Mangel1985, @Marescot2013]. 

The transition matrix is an expression of conditional probability $P(X_{t+1} | X_t,  A_t)$, the probability that a system in state $X_t$ will transition to state $X_{t+1}$ in the next time interval if the manager takes action $A_t$.  If we have $n$ possible states and $m$ possible actions, we have $m \phantom{\cdot} n \times n$ matrices for the possible transitions. The transition matrix also depends on our knowledge or estimates of the parameters of \eqref{model}. For simplicity, the examples here have assumed a grid of state space values as he integers between 0 to 120, and an equivalently fine grid of 121 possible actions (control levels).  This provides sufficient approximation to a continuous state space and action space, so that results are not sensitive to the details of this discritization.


```{r}
# Constants in the utility function
damage <- .5
control <- 1
endemic <- 50
discount <- 0.999 # Note that dynamics are not on scale of years but ~ days
reward_fn <- function(x,h) - (damage * pmax(x - endemic, 0)) ^ 2  - (control * h)

reward <- array(dim=c(length(states), length(actions)))
for(i in 1:length(states)){
  for(j in 1:length(actions)){
    reward[i,j] <- reward_fn(states[i], actions[j])
  }
}
```


## Optimal planning under transient dynamics vs stable state dynamics

First, let us consider the case that in which the manager has been able to accurately infer the dynamics (i.e. correctly estimate the parameters of Eq \eqref{model}, and assuming the model structure postulated \eqref{model} is correct.  The optimal strategy determined by SDP can be represented as a "policy" function $p(X)$, indicating for each possible state $X$ what the optimal action $\hat A = p(X)$ would be.  Fig 3 displays the numerically computed optimal policy for the system with only a transient.  Though the models differ by only a small amount in a single parameter, because one model corresponds to a system with only a ghost attractor while the other has a stable state attractor, the resulting optimal policy solutions differ significantly.  Intuitively, in the system with stable state dynamics, the manager does not implement any control at low levels, where the presence of the lower stable state will constrain the beetle population to acceptable levels.  Once that lower stable state becomes only a ghost attractor, the optimal solution targets elimination of the beetle even at low densities.  Consequently, the optimal response becomes tightly dependent on our knowledge of the dynamics. 


```{r mdp_solns}
soln_ghost <- mdplearning::mdp_compute_policy(list(P_ghost), reward, discount, max_iter = 1e4, epsilon = 1e-2)
soln_bistable <-mdplearning::mdp_compute_policy(list(P_bistable), reward, discount, max_iter = 1e4, epsilon = 1e-4)

## Identical calculation using MDPtoolbox implementation
#soln_ghost <-MDPtoolbox::mdp_value_iteration(P_ghost, reward, discount, max_iter = 5e3, epsilon = 1e-5)

```

```{r}
## With more noise, these are more similar.  With smaller noise, the ghost policy remains aggressive over a larger range
policy_plot <- 
  tibble(state = states,
         ghost = actions[soln_ghost$policy],
         bistable =  actions[soln_bistable$policy]
         ) %>%
  pivot_longer(c(ghost, bistable), 
               names_to="model",
               values_to = "action") 

write_csv(policy_plot, "manuscript_cache/policy_plot.csv")
```

```{r figure3, fig.cap="Optimal policy functions under each model. Parameter values for utility function used here are $c = 1$, $d = 0.5$, $X_0 = 50$, $\\delta = 0.999$, parameters for the transition models are as given in Fig 1."}
## Fig 3

policy_plot %>%
  ggplot(aes(state, action, color = model)) + 
  geom_point(alpha=0.6)
```


```{r}
reps <- 20
Tmax <- 200
set.seed(12345)
sim_ghost <- map_dfr(1:reps, function(i)
                   mdp_planning(P_ghost, reward, discount, 
                   policy = soln_ghost$policy,
                   x0 = x0, Tmax = Tmax), .id = "reps")
sim_bistable <- map_dfr(1:reps, function(i)
                   mdp_planning(P_ghost, reward, discount, 
                   policy = soln_bistable$policy,
                   x0 = x0, Tmax = Tmax), .id = "reps")

fixed_sims <- 
 bind_rows(ghost = sim_ghost, 
           bistable = sim_bistable, 
           .id = "prior") %>% 
  mutate(state = states[state], 
         action = actions[action]) 


fixed_sims %>% write_csv("manuscript_cache/fixed_sims.csv")
```

We can get a better idea of the consequences of mistaking the long transient dynamics for stable state dynamics by examining the dynamics of a system when it is actively managed according to the policy function for the wrong model.  It is important to note that even when the policy wrongly assumes the system has an endemic stable state (e.g. small beetle population density), this does not necessarily mean that the manager will never intervene and the dynamics will reach the high stable state unchecked. As we see in the policy function, at low densities, the alternative stable state policy does indeed choose to do nothing, since it expects the density to remain around an acceptable endemic level.  However, once the densities get high enough (the system escapes the ghost attractor), the manager intervenes -- but this intervention is only enough to restore the system to the endemic state.  This results in a pattern of perpetual interventions. Simulations of 10 independent realizations of a ghost-attractor system being managed with the optimal policy of the alternative stable state model (Fig 4, upper panel).

```{r figure4, fig.cap = "Simulations of dynamic management under each of the policy functions shown in Fig 3, when the true model is in fact the ghost attractor. We have used a common scale for both the state (beetle density) and action (control intensity), which range from 0 to 120, allowing us to display these on a common y-axis to reduce the number of panels. In general states and actions will be in different units. The manager who has incorrectly assumed the system is bistable allows the beetle to persist, but must take constant management action to maintain the population at the acceptable endemic size.  The manager who knows the dynamics are merely a long transient due to a ghost attractor immediately takes much more decisive action (compare costs, Fig 5) eliminate the beetle."}
# Fig 4
fixed_sims <- read_csv("manuscript_cache/fixed_sims.csv")

fixed_sims %>% select(state, action, time, prior, reps) %>%
  pivot_longer(c(-time, -prior, -reps), names_to = "line", values_to  = "state") %>%
  filter(time < 100) %>%
  ggplot(aes(time, state, group = interaction(line, reps), col=line)) + 
  geom_line(alpha=0.5) + 
  facet_wrap(~prior, ncol=1) + ylab("state or action")
```



  In contrast, had the manager known the system no longer supported the endemic stable state but had only a ghost attractor, the optimal policy is a costly up-front intervention which eliminates the beetle entirely (Fig 4, lower panel).  A comparison between the large up front cost of the optimally managed realizations to the ever rising costs of the mistaken case can be seen in Fig 5, shown in terms of net present value (i.e. cumulative costs, where future costs have been discounted by rate $\delta$.)  The examples shown here use a relatively small discount rate of 0.999 per unit time -- under sufficiently aggressive discounting this large up-front investment would not be optimal.  (Note that we use the term "small" meaning relative to the timescale shown, e.g. the value at time 200 is worth $0.999^{200} \approx 81.86\%$ of its starting value. As the units of time here correspond to the generation time of the beetle.)


```{r figure5, fig.cap="Average costs associated with control of the beetle over time under across the simulations shown in Fig 4.  Costs are in net present value: cumulative cost of management (in arbitrary units), discounting future values by the discount rate $\\delta$.  Observe that optimal management of the ghost attractor results in a large up-front investment in control, while incorrectly assuming the system is bistable results in control that is initially less costly but continues to accumulate over time."}
costs <- fixed_sims %>% group_by(time, prior)  %>% 
  summarise(cost = mean(value)) %>%
  group_by(prior) %>%
  mutate(cost = abs(cumsum(cost * .999 ^ time))) %>%
  rename(model = prior) 

costs %>%
  ggplot(aes(time, cost, ymin = 0, ymax = cost, fill=model)) +
  geom_ribbon(alpha = 0.5) +
  ylab("Cost (net present value)") + xlab("time")
```



## Planning over uncertainty

Rather than having to completely assume a given model, it is possible to reflect our uncertainty about which model is correct in our calculation of the optimal policy.   We can represent uncertainty over both the models and their given parameters conditionally: so that the transition matrix is marginalized over the set $M_i$ of possible models: 

$$P(X_{t+1} | X_t,  A_t) = \sum_{i} P(X_{t+1} | X_t,  A_t, M_i) P(M_i)$$


This requires we can assign probabilities that each model is true, which I will refer to as 'prior probabilities' for reasons that will be clear in the next section. In this way, our uncertainty about the future state reflects both the inherent uncertainty of the stochastic process as well as our ignorance of the particular model. For simplicity I will consider only the two specific models we have worked with so far, though this same approach could easily be extended to a suite of possible models.  If the two models are considered equally likely, the optimal policy in the case of our examples looks like an only slightly more aggressive version of the policy for the bistable system, as seen in the replicate simulations shown in Fig 6.  This policy eliminates the beetles in a few of the replicate simulations where the population dips enough to make that decision economical, but otherwise settles for persistent management, as shown in the upper panel.  However, we can also see that absolute certainty is not required for definitive action -- once we are sufficiently sure the system is a ghost attractor, e.g. 70% probability as shown in the lower panel of Fig 6, the optimal solution eliminates the pest immediately on all replicates.  Not surprisingly, the 50-50 case achieves a long run net present value that is intermediate to the optimal solution and the mistaken solution considered in Fig 5.  


```{r mdp_solns_mixed_prior}
fifty_fifty <- mdplearning::mdp_compute_policy(list(P_ghost, P_bistable), reward, discount, 
                                             model_prior = c(0.5, 0.5),
                                             max_iter = 1e4, epsilon = 1e-2)

seventy_thirty <- mdplearning::mdp_compute_policy(list(P_ghost, P_bistable), reward, discount, 
                                             model_prior = c(0.7, 0.3),
                                             max_iter = 1e4, epsilon = 1e-2)

```

```{r eval=FALSE}
## Fig not shown -- intermediate prior gives an intermediate policy
tibble(state = states,
       action = actions[fifty_fifty$policy])  %>% 
  ggplot(aes(state, action)) + geom_point() + 
  geom_vline(aes(xintercept = states[x0]))
```

```{r planning_sims}

sim_fiftyfifty <-  map_dfr(1:reps, function(i)
                   mdp_planning(P_ghost, reward, discount, 
                   policy = fifty_fifty$policy,
                   x0 = x0, Tmax = Tmax), .id = "reps")
sim_seventythirty <- map_dfr(1:reps, function(i)
                   mdp_planning(P_ghost, reward, discount, 
                   policy = seventy_thirty$policy,
                   x0 = x0, Tmax = Tmax), .id = "reps")

sims_by_prior <- 
 bind_rows(fifty_fifty = sim_fiftyfifty, 
           seventy_thirty = sim_seventythirty, 
           .id = "prior")  %>% 
  mutate(state = states[state], 
         action = actions[action]) 

sims_by_prior %>% write_csv("manuscript_cache/sims_by_prior.csv")

```

```{r figure6, fig.cap="Simulations of scenarios which reflect manager's uncertainty about the true model.  Upper panel: manager assumes both the ghost attractor and the bistable attractor models are equally probable.  Some of the 20 replicate simulations result in large actions that eliminate the pest, while most resemble management under the assumption of bistability.  Lower panel: manager assumes a 70\\% probability of a ghost attractor.  All 20 replicate simulations immediately opt to eliminate the beetle immediately in this scenario.  Note that as in Fig 4, y axis is used as a common scale for state and action."}
## Fig 6

sims_by_prior <- read_csv("manuscript_cache/sims_by_prior.csv")

sims_by_prior  %>% select(state, action, time, prior, reps) %>%
  pivot_longer(c(-time, -prior, -reps), names_to = "line", values_to  = "state") %>%
  filter(time < 100) %>%
  ggplot(aes(time, state, group = interaction(line, reps), col=line)) + 
  geom_line(alpha=0.5) + 
  facet_wrap(~prior, ncol=1)
```


## Adaptive management

In the scenarios we have just considered, the manager continues to apply the same optimal decision rule over the entire management period.  This does not, of course, mean that the management response is completely static -- in fact, the manager selects a different the intervention level at each time-step in response to updated information about the current beetle population size -- but the manager does not use that information to revisit the underlying assumptions about the appropriate model. However, each additional observation potentially provides further information about which model is correct.  After enough attempts to restore the population to a stable endemic state only to have another outbreak follow, we might expect our manager to realize that the endemic state just isn't as stable as originally thought.  More formally, we might assume the manager would update that initial prior belief over the possible models according to Bayes Rule, 

$$P(M_i | X_{t+1} ) = \frac{P(X_{t+1} | M_i ) P(M_i)}{P(X_{t+1})}$$
In other words, our optimal manager not only plans over the uncertainty, but also learns which model is most likely to be correct over the course of management.  This approach corresponds to Carl Walters' original notion of "adaptive management" [@Walters1978]. (Note that the term is now used much more loosely, and would commonly include the kind of decision rule shown previously where the decision is adjusted based on future observations.).  This approach is considerably more computationally intensive, since the stochastic dynamic programming problem must be solved again at each time step after the model weights have been updated. Fig 7 illustrates a typical outcome of adaptive management starting with the uniform prior (equal weights on both models): a short period of modest intervention while the manager learns which model is more likely to be correct, followed by a more decisive intervention once the long transient becomes sufficiently likely.  Of course, this defensive action also eliminates the potential for future learning, so the manager can never be completely sure this action was necessary, as shown by the model probabilities in Fig 8.  This represents a form of precautionary principle already suggested by the purely planning approach considered in the previous section -- the manager need not be certain about the correct model, but merely reach a certain threshold of probability.



```{r mdp_learning}
set.seed(12345)
Tmax <- 50
learning <- mdp_learning(list(P_ghost, P_bistable), reward, discount, 
                   model_prior = c(0.5, 0.5),
                   x0 = x0, Tmax = Tmax,
                  true_transition = P_ghost,
                  max_iter = 1e4, epsilon = 1e-2)
                  
write_csv(learning$df, "manuscript_cache/learning_df.csv")
write_csv(learning$posterior, "manuscript_cache/learning_posterior.csv")
```



```{r figure7, fig.cap="Simulated adaptive management of the forest-beetle system.  Initally each model is considered equally likely, and management aims at retaining a stable endemic population.  The manager learns over time (Fig 8), and decides to take more definitive action to eliminate the beetle pest."}
# Fig 7
 learning$df %>% 
  select(-value, -obs) %>% 
  gather(series, state, -time) %>% 
  ggplot(aes(time, states[state], color = series)) + geom_line() + ylab("state or action")
```



```{r figure8, fig.cap="Learning through Adaptive Management of the forest-beetle system. Bars show the probabilities that each model is correct over the first 10 steps of the simulated management process shown in Fig 7.  Initial probabilities for each model are equal, and learning proceeds over the first 5 timesteps (shown in lighter shades in decreasing probability of the bistable model beign correct).  By the fifth iteration, the manager has opted to eliminate the beetles and further learning is no longer possible in this system."}
model_names <- c("Ghost", "Bistable")
learning$posterior %>% 
  data.frame(time = 1:Tmax) %>%
  filter(time %in% floor(seq(1,10, length.out=5))) %>%
  gather(param, probability, -time, factor_key =TRUE) %>% 
  mutate(param = model_names[as.integer(param)]) %>% 
  ggplot(aes(x = param, y = probability, group = time, alpha = time)) + 
  geom_bar(stat="identity", position = "identity", show.legend = FALSE, fill=pal[1]) + 
  xlab("Model")
```



# Discussion


While the importance of long transients to ecological dynamics is now being recognized, greater understanding of the consequences this realization has for ecological management is still needed. For instance, @Hastings2018 discusses the potential implications that long transients have the management of ecosystems, including the situation we have considered here:

> In other cases, when it is difficult to distinguish whether observed dynamics are transient or at equilibrium, models of both possibilities can be developed to test the sensitivity of proposed management strategies to the model assumptions,

while also calling for closer study of those consequences:

> A full treatment of the management consequences and opportunities presented by long transients re- quires further attention

In this analysis, I have attempted to provide a more detailed treatment of the management consequences of just such a long transient by focusing on a minimal model capable of producing ghost-attractor dynamics.  This model captures common ecological management scenarios, such as the outbreak of a bark beetle pest we have focused on here, and could easily be generalized to other typical ecological management problems which also involve tipping-point dynamics.  As the name implies, ecological *management* is typically not a single decision-point, but rather, a *sequential decision process*, where a manager implements a policy over time and may adjust that policy in response to future observations.  I have drawn on methods from optimal control theory, stochastic dynamic programming in particular, to explore how a manager responds to the possible outbreak of a bark beetle infestation when there is uncertainty as to whether the observed dynamics are a transient or equilibrium phase.  

From this analysis, several conclusions emerge.  First, we have a clear illustration of just how misleading long transient dynamics can appear -- without access to multiple replicate realizations (which is nearly always the case in real systems), distinguishing between transient dynamics and stable dynamics in the same system from purely observational data will always be difficult. (A more formal consideration of this statistical inference problem is treated in Reimer et al., intended for this same issue of Theoretical Ecology). Second, we see that this miss-identification leads to qualitatively different management outcomes, even when management is dynamic and following an optimal policy for a closely related model.  In particular, in our example, a manager accumulates an ever-growing cost of coping with the outbreak while never fully eliminating the threat.  

Despite these differences, we have also seen that dynamic and adaptive management approaches can nevertheless be an effective mechanism to cope with the uncertainty posed by long transients.  First, it is important to note that all dynamic management scenarios succeed in preventing the outbreak even without the correct model.  Because an outbreak is still possible under the stable state scenario due to stochastic tipping, the optimal manager still responds to high beetle densities.  This highlights the importance of properly understanding the management context and the decision space in order to understand management implications -- management is a socio-ecological problem and can never be understood from the ecological dimension alone.  

Second, we observe that a manager can build the uncertainty over the two scenarios into the decision process.  Once there is sufficient probability that the system is in a long transient sustained by a ghost attractor rather than in a true equilibrium, the manager reaches the identical optimal policy as would a manager with perfect knowledge of which model is correct.  Perfect information is not required for perfect management.  We see a second illustration of this fact when we consider an adaptive management approach, which attempts to learn the true model over the course of management.  Adaptive management does indeed allow the manager to correctly adjust probabilities each model is true.  However, learning does not continue indefinitely, since once the probability of a ghost attractor becomes high enough, the manager eliminates the beetles and with it, any potential for further learning.


Several caveats about this analysis must be noted.  First, I underscore that this is not intended to be a precise model of bark beetle dynamics, but rather a general model  [sensu @Levins1966] to explore the management consequences of confusing a ghost attractor for an alternative stable state.  A precise model would depend on ecological details of forest and beetle dynamics (including spatially explicit dynamics), as well as the details of management interventions and associated costs. Parameter values have been chosen to be illustrative of the region of interest where a ghost attractor could be mistaken for a weakly bistable system.  Extreme values of the parameters will alter the qualitative patterns seen here.  For instance, very large environmental noise intensity ($\sigma$), erode any differences between the ghost and the weakly bistable system, since escapes from the low density, endemic state become commonplace.  Likewise, extreme values of the costs of control or costs of tree damage can also make the decision problem trivial, where intervention is never worthwhile or always worthwhile.  The examples here focus on the more ecologically typical region where management is not trivial.


Another caveat regards the inevitable simplifying assumptions we have introduced to maintain a tractable system.  We have assumed that while our manager does not know whether the system has multiple equilibria or a ghost attractor, the manager does know most other details about the system. In particular, we have assumed the manager observes the current population size without error before each action.  In reality, any such observation would be accompanied by some uncertainty, making the decision problem into a Partially Observed Markov Decision Process (POMDP), increasing the complexity dramatically [e.g. @pomdp-intro].  We have also assumed the manager has knowledge of the general model structure.  This assumption can be relaxed in much the same way in which introduced model uncertainty, allowing one to consider an arbitrary suite of models (i.e. varying the parameter $a$ over a range of values, as well as to models with completely different structure).  However, the curse of dimensionality imposes obvious limitations on this.  Moreover, the approach assumes that while the ecological dynamics can be transient, the environment in which they occur is stationary (i.e. model parameters are constant.)  It is worth noting that these all of these issues in Markov Decision Processes are active areas of research in the robotics and artificial intelligence community, and recent advances in reinforcement learning could provide a promising way forward for many ecological management problems as well [e.g. @pnas; or see @deep-rl for an overview].  


# Numerical Methods

Stochastic dynamic programming solutions were computed in R [@R] using the value iteration stochastic dynamic programming algorithm [@Mangel1985; @Marescot2013].  Generic R functions for the stochastic dynamic programming, including both planning over model uncertainty and adaptive management for actively learning over model uncertainty, are supplied in the supplementary R package `mdplearning`, available at <https://github.com/boettiger-lab/mdplearning>, v0.1.0 [@mdplearning].  Code to reproduce the analysis, simulations and figures shown here can be found at <https://github.com/cboettig/decisions-vs-transients>.  

# Acknowledgements

This work was inspired and influenced many discussions at the 2019 NIMBioS workshop on transient dynamics in ecology, and the 2019 organized oral session on ecological transients.  CB also acknowledges computational resources from NSF's XSEDE Jetstream (DEB160003) and Chameleon cloud platforms, as well as the support from UC Berkeley and the USDA Hatch project CA-B-INS-0162-H.


\pagebreak 


# References